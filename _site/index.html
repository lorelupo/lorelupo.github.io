
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 12px;
    font-weight: 400
  }
  heading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 19px;
    font-weight: 1000
  }
  strong {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 800
  }
  strongred {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    font-weight: 600
  }
  </style>
  <link rel="icon" type="image/png" href="images/broccolo.png">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Lorenzo Lupo</title>
  <meta name="Lorenzo Lupo's Homepage" http-equiv="Content-Type" content="Lorenzo Lupo's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- Start : Google Analytics Code -->
  <!-- <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'MIOCODICEQUI', 'auto');
    ga('send', 'pageview');
  </script> -->
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>

<body>
  <table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="10">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
            <td width="25%"><a target="_blank" href="images/rafael_valle.png"><img src="images/lorenzo_lupo.jpeg" width="100%"></a></td>
            <td width="67%" valign="top" align="justify">
              <p align="left"><font size="7">Lorenzo Lupo</font><br>
                <b>Email</b>:
                <font id="email" style="display:inline;">
                  <noscript><i>Please enable Javascript to view</i></noscript>
                </font>
                <script>
                  emailScramble = new scrambledString(document.getElementById('email'),
                      'emailScramble', 'pnzerl-@eioroapbennf-soevullrugo.l.',
                      [10, 4, 5, 30, 2, 8, 26, 12, 25, 15, 22, 34, 6, 27, 29, 23, 20, 14, 21, 33, 17, 31, 1, 3, 16, 9, 24, 0, 19, 13, 18, 11, 7, 28, 32]);
                  </script>
              <p>I'm a soon-to-graduate PhD student in natural language processing at Université Grenoble-Alpes,
                team <a target="_blank" href="https://lig-getalp.imag.fr/">GETALP</a>. In the last three years, I focused on 
              context-aware neural machine translation, aiming to bridge the gap between machine and human translators.
              <a target="_blank" href="http://lig-membres.imag.fr/besacier/">Laurent Besacier</a> and
              <a target="_blank" href="http://www.marcodinarelli.it/">Marco Dinarelli</a> supervised and supported me along this journey.
              Previously, I have worked on Grammatical Error Correction at <a target="_blank" href="https://indigo.ai/en/">Indigo AI</a>
              and reinforcement learning with <a target="_blank" href="https://scholar.google.com/citations?user=xdgxRiEAAAAJ&hl=en">Marcello Restelli</a>.
              Besides research in machine learning, I mostly study and practice meditation, and try to be a good friend and husband.
              Oh, you might also want to check our (me and my family) <a target="_blank" href="https://fagiolini.github.io">blog on easy vegan cuisine</a>. <p>
              <p align=left>
              <a target="_blank" href="Lorenzo_Lupo_CV.pdf">CV</a> | 
              <a target="_blank"href="https://www.linkedin.com/in/lupo-lorenzo/?originalSubdomain=it"> LinkedIn </a>|
              <a target="_blank" href="http://www.github.com/lorelupo"> GitHub </a>|
              <a target="_blank" href="https://scholar.google.com/citations?user=X3KOx8UAAAAJ&hl=fr"> Scholar </a> |
              <a target="_blank" href="https://fagiolini.github.io"> fagiolini </a>
              </p>
            </td>
        </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
      <tr><td><sectionheading>Talks</sectionheading></td></tr>
    </table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">

  <tr>
    <td width="100%" valign="top">
      <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
      07/12/2022 <b>Focused concatenation for context-aware neural machine translation.</b></a><br>
      @<a target="_blank" href="https://www.statmt.org/wmt22/">EMNLP 2022 7th Conference on Machine Translation</a>, Abu Dhabi, United Arab Emirates.<br>
      <br>
      23/06/2022 <b>Divide&Rule: pre-training for context-aware multi-encoder translation models.</b></a><br>
      @<a target="_blank" href="https://europe.naverlabs.com/">Naver Labs Europe</a>, Grenoble, France.<br>
      <br>
      05/10/2021 <b>Divide&Rule: pre-training for context-aware multi-encoder translation models.</b></a><br>
      @<a target="_blank" href="https://europe.naverlabs.com/">Naver Labs Europe</a>, Grenoble, France.<br>
      <br>
      05/10/2021 <b>Recent advances in document-level neural machine translation.</b></a><br>
      @<a target="_blank" href="https://lig-getalp.imag.fr/">LIG-GETALP</a>, Grenoble, France.<br>
    </td>
  </tr>
  <tr>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>Teaching</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">

  <tr>
    <!-- <td width="33%" valign="top" align="center"><a target="_blank" href="https://github.com/lorelupo/tp_nlp"><img src="images/polytech.png" alt="sym" width="50%" style="border-style: none"></img> -->
    <td width="100%" valign="top">
      01/2022 - 04/2022 <b>Communication langagière / natural language processing</b> (excercice classes, M1)</a><br>
      @<a target="_blank" href="https://formations.univ-grenoble-alpes.fr/fr/catalogue-2021/cycle-preparatoire-et-diplome-d-ingenieur-XC/ingenieur-de-polytech-grenoble-specialite-informatique-ricm-IAS4L3XU/ue-texte-et-donnees-text-and-data-IH1TB9TW/communication-langagiere-natural-language-processing-IH1TCT6P.html">
          Polytech Grenoble - University Grenoble Alpes</a> | <a target="_blank" href="https://github.com/lorelupo/tp_nlp">assignments</a><br>
      <br>
      01/2022 - 04/2022 <b>Natural language processing for finance</b> (excercice classes, M2) </a><br>
      @<a target="_blank" href="https://ensimag.grenoble-inp.fr/fr/formation/natural-language-and-speech-processing-wmm9mo26-1">
        ENSIMAG - University Grenoble Alpes | <a target="_blank" href="https://github.com/lorelupo/tp_nlp">assignments</a><br>
      <br>
      01/2021 - 04/2021 <b>Communication langagière / natural language processing</b> (excercice classes, M1)</a><br>
      @<a target="_blank" href="https://formations.univ-grenoble-alpes.fr/fr/catalogue-2021/cycle-preparatoire-et-diplome-d-ingenieur-XC/ingenieur-de-polytech-grenoble-specialite-informatique-ricm-IAS4L3XU/ue-texte-et-donnees-text-and-data-IH1TB9TW/communication-langagiere-natural-language-processing-IH1TCT6P.html">
          Polytech Grenoble - University Grenoble Alpes</a> | <a target="_blank" href="https://github.com/lorelupo/tp_nlp">assignments</a><br>
      <br>
      01/2021 - 04/2021 <b>Natural language processing for finance</b> (excercice classes, M2) </a><br>
      @<a target="_blank" href="https://ensimag.grenoble-inp.fr/fr/formation/natural-language-and-speech-processing-wmm9mo26-1">
        ENSIMAG - University Grenoble Alpes | <a target="_blank" href="https://github.com/lorelupo/tp_nlp">assignments</a><br>
      <br>
    </td>
  </tr>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>Publications</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">


  <tr>
    <td width="33%" valign="top" align="center"><a target="_blank" href="https://arxiv.org/abs/2210.13388"><img src="images/focused.png" alt="sym" width="100%" style="border-style: none"></img>
    <td width="67%" valign="top">
      <p><a target="_blank" href="https://arxiv.org/abs/2210.13388" id="SPLIT">
      <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
      <strong>Focused Concatenation for Context-Aware Neural Machine Translation</strong></a><br>
      <strong>Lorenzo Lupo</strong>, Marco Dinarelli, Laurent Besacier<br>
      <em>ACL</em>, 2022
      </p>
      <div class="paper" id="split">
        <a target="_blank" href="https://arxiv.org/pdf/2210.13388.pdf">pdf</a> | 
        <a href="javascript:toggleblock('split_abs')">abstract</a>  |
        <a shape="rect" href="javascript:togglebib('split')" class="togglebib">bibtex</a> |
        <a target="_blank" href="https://github.com/lorelupo/focused-concat">code</a> 
        <p align="justify"> <i id="split_abs">A straightforward approach to context-aware neural machine translation  consists in feeding the standard encoder-decoder architecture with a window of  consecutive sentences, formed by the current sentence and a number of sentences from its context concatenated to it. In this work, we propose an improved concatenation approach that encourages the model to focus on the translation of the current sentence, discounting the loss generated by target context. We also propose an additional improvement that strengthen the notion of sentence boundaries and of relative sentence distance, facilitating model compliance to the context-discounted objective. We evaluate our approach with both average-translation quality metrics and contrastive test sets for the translation of inter-sentential discourse phenomena, proving its superiority to the vanilla concatenation approach and other sophisticated context-aware systems. </i></p>
        <pre xml:space="preserve">
          @misc{https://doi.org/10.48550/arxiv.2210.13388,
            doi = {10.48550/ARXIV.2210.13388},
            url = {https://arxiv.org/abs/2210.13388},
            author = {Lupo, Lorenzo and Dinarelli, Marco and Besacier, Laurent},
            keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
            title = {Focused Concatenation for Context-Aware Neural Machine Translation},
            publisher = {arXiv},
            year = {2022},
            copyright = {Creative Commons Attribution 4.0 International}
          }       
        </pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="top" align="center"><a target="_blank" href="https://aclanthology.org/2022.acl-long.312/"><img src="images/multienc.jpeg" alt="sym" width="100%" style="border-style: none"></img>
    <td width="67%" valign="top">
      <p><a target="_blank" href="https://aclanthology.org/2022.acl-long.312/" id="SPLIT">
      <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
      <strong>Divide and Rule: Effective Pre-Training for Context-Aware Multi-Encoder Translation Models</strong></a><br>
      <strong>Lorenzo Lupo</strong>, Marco Dinarelli, Laurent Besacier<br>
      <em>ACL</em>, 2022
      </p>
      <div class="paper" id="split">
        <a target="_blank" href="https://aclanthology.org/2022.acl-long.312.pdf">pdf</a> | 
        <a href="javascript:toggleblock('split_abs')">abstract</a>  |
        <a shape="rect" href="javascript:togglebib('split')" class="togglebib">bibtex</a> |
        <a target="_blank" href="https://github.com/lorelupo/divide-and-rule">code</a> 
        <p align="justify"> <i id="split_abs">Multi-encoder models are a broad family of context-aware neural machine translation systems that aim to improve translation quality by encoding document-level contextual information alongside the current sentence. The context encoding is undertaken by contextual parameters, trained on document-level data. In this work, we discuss the difficulty of training these parameters effectively, due to the sparsity of the words in need of context (i.e., the training signal), and their relevant context. We propose to pre-train the contextual parameters over split sentence pairs, which makes an efficient use of the available data for two reasons. Firstly, it increases the contextual training signal by breaking intra-sentential syntactic relations, and thus pushing the model to search the context for disambiguating clues more frequently. Secondly, it eases the retrieval of relevant context, since context segments become shorter. We propose four different splitting methods, and evaluate our approach with BLEU and contrastive test sets. Results show that it consistently improves learning of contextual parameters, both in low and high resource settings. </i></p>
        <pre xml:space="preserve">
          @inproceedings{lupo-etal-2022-divide,
            title = "Divide and Rule: Effective Pre-Training for Context-Aware Multi-Encoder Translation Models",
            author = "Lupo, Lorenzo  and
              Dinarelli, Marco  and
              Besacier, Laurent",
            booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
            month = may,
            year = "2022",
            address = "Dublin, Ireland",
            publisher = "Association for Computational Linguistics",
            url = "https://aclanthology.org/2022.acl-long.312",
            doi = "10.18653/v1/2022.acl-long.312",
            pages = "4557--4572",
            abstract = "Multi-encoder models are a broad family of context-aware neural machine translation systems that aim to improve translation quality by encoding document-level contextual information alongside the current sentence. The context encoding is undertaken by contextual parameters, trained on document-level data. In this work, we discuss the difficulty of training these parameters effectively, due to the sparsity of the words in need of context (i.e., the training signal), and their relevant context. We propose to pre-train the contextual parameters over split sentence pairs, which makes an efficient use of the available data for two reasons. Firstly, it increases the contextual training signal by breaking intra-sentential syntactic relations, and thus pushing the model to search the context for disambiguating clues more frequently. Secondly, it eases the retrieval of relevant context, since context segments become shorter. We propose four different splitting methods, and evaluate our approach with BLEU and contrastive test sets. Results show that it consistently improves learning of contextual parameters, both in low and high resource settings.",
        }        
        </pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="top" align="center"><a target="_blank" href="http://proceedings.mlr.press/v97/papini19a"><img src="images/optimist.png" alt="sym" width="100%" style="border-style: none"></a>
    <td width="67%" valign="top">
      <p><a target="_blank" href="http://proceedings.mlr.press/v97/papini19a" id="OPTIMIST">
      <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
      <strong>Optimistic Policy Optimization via Multiple Importance Sampling</strong></a><br>
      Matteo Papini, Alberto Metelli, <strong>Lorenzo Lupo</strong>, Marcello Restelli<br>
      <em>ICML</em>, 2019
      <br></p>
  
      <div class="paper" id="optimist">
        <a target="_blank" href="http://proceedings.mlr.press/v97/papini19a/papini19a.pdf">pdf</a> | 
        <a href="javascript:toggleblock('optimist_abs')">abstract</a>  |
        <a shape="rect" href="javascript:togglebib('optimist')" class="togglebib">bibtex</a> |
        <a target="_blank" href="https://github.com/lorelupo/optimist">code</a> 
        <p align="justify"> <i id="optimist_abs">Policy Search (PS) is an effective approach to Reinforcement Learning (RL) for solving control tasks with continuous state-action spaces. In this paper, we address the exploration-exploitation trade-off in PS by proposing an approach based on Optimism in the Face of Uncertainty. We cast the PS problem as a suitable Multi Armed Bandit (MAB) problem, defined over the policy parameter space, and we propose a class of algorithms that effectively exploit the problem structure, by leveraging Multiple Importance Sampling to perform an off-policy estimation of the expected return. We show that the regret of the proposed approach is bounded by O(sqrt(T)) for both discrete and continuous parameter spaces. Finally, we evaluate our algorithms on tasks of varying difficulty, comparing them with existing MAB and RL algorithms.</i></p>
        <pre xml:space="preserve">
          @InProceedings{pmlr-v97-papini19a,
            title = 	 {Optimistic Policy Optimization via Multiple Importance Sampling},
            author =       {Papini, Matteo and Metelli, Alberto Maria and Lupo, Lorenzo and Restelli, Marcello},
            booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
            pages = 	 {4989--4999},
            year = 	 {2019},
            editor = 	 {Kamalika Chaudhuri and Ruslan Salakhutdinov},
            volume = 	 {97},
            series = 	 {Proceedings of Machine Learning Research},
            address = 	 {Long Beach, California, USA},
            month = 	 {09--15 Jun},
            publisher =    {PMLR},
            pdf = 	 {http://proceedings.mlr.press/v97/papini19a/papini19a.pdf},
            url = 	 {http://proceedings.mlr.press/v97/papini19a.html},
          }     
        </pre>
      </div>
      </td>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                The code for this page is available <a href="https://github.com/lorelupo/lorelupo.github.io">here</a>. <br>
                Credits to <a href="https://jonbarron.info/">Jon Barron</a> for the template.
              </p>
            </td>
          </tr>
        </tbody>
      </table>

  </tr> 

</table>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
hideallabs();
</script>
</body>

</html>
