
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Deepak Pathak, Jon Barron and Abhishek Kar and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  heading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 19px;
    font-weight: 1000
  }
  strong {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 800
  }
  strongred {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    font-weight: 600
  }
  </style>
  <link rel="icon" type="image/png" href="images/broccolo.png">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Lorenzo Lupo</title>
  <meta name="Lorenzo Lupo's Homepage" http-equiv="Content-Type" content="Lorenzo Lupo's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- Start : Google Analytics Code -->
  <!-- <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'MIOCODICEQUI', 'auto');
    ga('send', 'pageview');
  </script> -->
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>

<body>
<table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center"><font size="7">Lorenzo Lupo</font><br>
    <b>Email</b>:
    <font id="email" style="display:inline;">
      <noscript><i>Please enable Javascript to view</i></noscript>
    </font>
    <script>
      emailScramble = new scrambledString(document.getElementById('email'),
          'emailScramble', 'pnzerl-@eioroapbennf-soevullrugo.l.',
          [10, 4, 5, 30, 2, 8, 26, 12, 25, 15, 22, 34, 6, 27, 29, 23, 20, 14, 21, 33, 17, 31, 1, 3, 16, 9, 24, 0, 19, 13, 18, 11, 7, 28, 32]);
      </script>
  </p>

  <tr>
    <td width="67%" valign="middle" align="justify">
    <p>I'm a PhD student in natural language processing at Universit√© Grenoble-Alpes,
      team <a target="_blank" href="https://lig-getalp.imag.fr/">GETALP</a>. I currently focus on 
    context-aware neural machine translation to bridge the gap between machine and human translators.
    <a target="_blank" href="http://lig-membres.imag.fr/besacier/">Laurent Besacier</a> and
    <a target="_blank" href="http://www.marcodinarelli.it/">Marco Dinarelli</a> supervise and support me along this journey.<p>
    <p align=center>
    <a target="_blank" href="Lorenzo_Lupo_CV.pdf">CV</a> | 
    <a target="_blank"href="https://www.linkedin.com/in/lupo-lorenzo/?originalSubdomain=it"> LinkedIn </a>|
    <a target="_blank" href="http://www.github.com/lorelupo"> github </a>
    </p>
    </td>

    <td width="33%"><a target="_blank" href="images/rafael_valle.png"><img src="images/lorenzo_lupo.jpeg" width="90%"></a></td>
  </tr>
</table>

<!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>
    <sectionheading>News</sectionheading>
    <ul>     
    <li> <a href="#BUONANUOVA">Paper</a> ficoooooooooooooooooooo. </li>
    <li> <a href="#BUONANUOVA2">Paper</a> ficoooooooooooooooooooo2. </li>

    </ul>
  </td></tr>
</table> -->

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td><sectionheading>Publications</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

  <tr>
    <td width="33%" valign="top" align="center"><a target="_blank" href="https://arxiv.org/abs/2103.17151"><img src="images/multienc.jpeg" alt="sym" width="100%" style="border-style: none"></img>
    <td width="67%" valign="top">
      <p><a target="_blank" href="https://arxiv.org/abs/2103.17151" id="SPLIT">
      <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
      <heading>Divide and Rule: Training Context-Aware Multi-Encoder Translation Models with Little Resources</heading></a><br>
      <strong>Lorenzo Lupo</strong>, Marco Dinarelli, Laurent Besacier<br>
      <em>arXiv</em>, 2021
      <br></p>
  
      <div class="paper" id="split">
        <a target="_blank" href="https://arxiv.org/pdf/2103.17151.pdf">pdf</a> | 
        <a href="javascript:toggleblock('split_abs')">abstract</a>  |
        <a shape="rect" href="javascript:togglebib('split')" class="togglebib">bibtex</a>
        <p align="justify"> <i id="split_abs">Multi-encoder models are a broad family of context-aware Neural Machine Translation (NMT) systems that aim to improve translation quality by encoding document-level contextual information alongside the current sentence. The context encoding is undertaken by contextual parameters, trained on document-level data. In this work, we show that training these parameters takes large amount of data, since the contextual training signal is sparse. We propose an efficient alternative, based on splitting sentence pairs, that allows to enrich the training signal of a set of parallel sentences by breaking intra-sentential syntactic links, and thus frequently pushing the model to search the context for disambiguating clues. We evaluate our approach with BLEU and contrastive test sets, showing that it allows multi-encoder models to achieve comparable performances to a setting where they are trained with x10 document-level data. We also show that our approach is a viable option to context-aware NMT for language pairs with zero document-level parallel data.</i></p>
        <pre xml:space="preserve">
          @misc{lupo2021divide,
            title={Divide and Rule: Training Context-Aware Multi-Encoder Translation Models with Little Resources}, 
            author={Lorenzo Lupo and Marco Dinarelli and Laurent Besacier},
            year={2021},
            eprint={2103.17151},
            archivePrefix={arXiv},
            primaryClass={cs.CL}
          }     
        </pre>
      </div>
    </td>
  </tr>


  <tr>
    <td width="33%" valign="top" align="center"><a target="_blank" href="http://proceedings.mlr.press/v97/papini19a"><img src="images/optimist.png" alt="sym" width="100%" style="border-style: none"></a>
    <td width="67%" valign="top">
      <p><a target="_blank" href="http://proceedings.mlr.press/v97/papini19a" id="OPTIMIST">
      <!-- <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none"> -->
      <heading>Optimistic Policy Optimization via Multiple Importance Sampling</heading></a><br>
      Matteo Papini, Alberto Metelli, <strong>Lorenzo Lupo</strong>, Marcello Restelli<br>
      <em>ICML</em>, 2019
      <br></p>
  
      <div class="paper" id="optimist">
        <a target="_blank" href="http://proceedings.mlr.press/v97/papini19a/papini19a.pdf">pdf</a> | 
        <a href="javascript:toggleblock('optimist_abs')">abstract</a>  |
        <a shape="rect" href="javascript:togglebib('optimist')" class="togglebib">bibtex</a> |
        <a target="_blank" href="https://github.com/lorelupo/optimist">code</a> 
        <p align="justify"> <i id="optimist_abs">Policy Search (PS) is an effective approach to Reinforcement Learning (RL) for solving control tasks with continuous state-action spaces. In this paper, we address the exploration-exploitation trade-off in PS by proposing an approach based on Optimism in the Face of Uncertainty. We cast the PS problem as a suitable Multi Armed Bandit (MAB) problem, defined over the policy parameter space, and we propose a class of algorithms that effectively exploit the problem structure, by leveraging Multiple Importance Sampling to perform an off-policy estimation of the expected return. We show that the regret of the proposed approach is bounded by O(sqrt(T)) for both discrete and continuous parameter spaces. Finally, we evaluate our algorithms on tasks of varying difficulty, comparing them with existing MAB and RL algorithms.</i></p>
        <pre xml:space="preserve">
          @InProceedings{pmlr-v97-papini19a,
            title = 	 {Optimistic Policy Optimization via Multiple Importance Sampling},
            author =       {Papini, Matteo and Metelli, Alberto Maria and Lupo, Lorenzo and Restelli, Marcello},
            booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
            pages = 	 {4989--4999},
            year = 	 {2019},
            editor = 	 {Kamalika Chaudhuri and Ruslan Salakhutdinov},
            volume = 	 {97},
            series = 	 {Proceedings of Machine Learning Research},
            address = 	 {Long Beach, California, USA},
            month = 	 {09--15 Jun},
            publisher =    {PMLR},
            pdf = 	 {http://proceedings.mlr.press/v97/papini19a/papini19a.pdf},
            url = 	 {http://proceedings.mlr.press/v97/papini19a.html},
          }     
        </pre>
      </div>
    </td>
  </tr> 

</table>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('optimist_abs');
</script>
</body>

</html>
